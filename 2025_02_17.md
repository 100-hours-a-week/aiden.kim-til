# 📘 미분 복습 및 개념 정리

## 📌 1. 기준 변화와 변화량

- **변화량**: 함수의 입력값이 변할 때 함수 값이 변하는 정도.
- **평균 변화율**: 두 점 사이에서 함수의 변화율을 측정하는 값.
- **순간 변화율 (미분계수)**: 특정 순간에서의 변화량으로, 미분의 기본 개념.

### ✅ 평균 변화율

평균 변화율은 두 점 `(x, f(x))`와 `(x + \Delta x, f(x + \Delta x))` 사이에서의 기울기.

\[
\frac{f(x+\Delta x) - f(x)}{\Delta x}
\]

### ✅ 순간 변화율 (미분계수)

평균 변화율에서 **극한을 취하면**, 순간 변화율(미분계수)이 됨.

\[
f'(x) = \lim\_{\Delta x \to 0} \frac{f(x + \Delta x) - f(x)}{\Delta x}
\]

---

## 📌 2. 미분법 (도함수 구하는 법)

### ✅ 기본 미분 법칙

1. **거듭제곱 법칙**:
   \[
   \frac{d}{dx} [x^n] = n \cdot x^{n-1}
   \]

2. **합의 미분법**:
   \[
   (f + g)' = f' + g'
   \]

3. **곱의 미분법**:
   \[
   (fg)' = f'g + fg'
   \]

4. **몫의 미분법**:
   \[
   \left( \frac{f}{g} \right)' = \frac{f'g - fg'}{g^2}
   \]

5. **연쇄법칙 (Chain Rule)**:
   \[
   \frac{d}{dx} f(g(x)) = f'(g(x)) \cdot g'(x)
   \]

### ✅ 지수 함수와 로그 함수의 미분

1. **지수 함수**:
   \[
   \frac{d}{dx} e^x = e^x, \quad \frac{d}{dx} a^x = a^x \ln a
   \]

2. **로그 함수**:
   \[
   \frac{d}{dx} \ln x = \frac{1}{x}, \quad \frac{d}{dx} \log_a x = \frac{1}{x \ln a}
   \]

### ✅ 삼각 함수의 미분

1. **사인 함수**:
   \[
   \frac{d}{dx} \sin x = \cos x
   \]

2. **코사인 함수**:
   \[
   \frac{d}{dx} \cos x = -\sin x
   \]

3. **탄젠트 함수**:
   \[
   \frac{d}{dx} \tan x = \sec^2 x
   \]

---

## 📌 3. 다변수 함수의 미분

### ✅ 편미분 (Partial Derivative)

- 다변수 함수에서 **특정 변수**에 대해서만 미분하는 것.

\[
\frac{\partial f}{\partial x}, \quad \frac{\partial f}{\partial y}
\]

- 예제:

\[
f(x, y) = x^2 + 3xy + y^2
\]

\[
\frac{\partial f}{\partial x} = 2x + 3y, \quad \frac{\partial f}{\partial y} = 3x + 2y
\]

### ✅ 방향 미분 (Directional Derivative)

- 어떤 방향 **\( \mathbf{v} = (v_1, v_2) \)** 에 대해 미분하는 방법.

\[
D\_{\mathbf{v}} f = \nabla f \cdot \mathbf{v} = \frac{\partial f}{\partial x} v_1 + \frac{\partial f}{\partial y} v_2
\]

### ✅ 그레디언트 (Gradient)

- 함수 \( f(x, y) \) 의 **가장 빠르게 증가하는 방향을 나타내는 벡터**.

\[
\nabla f = \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \right)
\]

---

## 📌 4. 야코비 행렬 (Jacobian Matrix)

- 벡터 함수 \( f: \mathbb{R}^n \to \mathbb{R}^m \) 에 대한 미분을 **행렬로 표현**.

\[
J_f =
\begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \cdots & \frac{\partial f_1}{\partial x_n} \\
\frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \cdots & \frac{\partial f_2}{\partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial x_1} & \frac{\partial f_m}{\partial x_2} & \cdots & \frac{\partial f_m}{\partial x_n}
\end{bmatrix}
\]

---

## 📌 5. 경사 하강법 (Gradient Descent)

- 손실 함수(Loss Function) \( f(w) \) 를 최소화하기 위한 방법.
- **그레디언트(Gradient) 방향이 가장 빠르게 증가하는 방향** → 반대 방향으로 이동.

\[
w := w - \alpha \nabla f(w)
\]

여기서,

- \( \alpha \) (학습률, Learning Rate)는 이동 속도를 조절하는 값.

---

## 📌 6. 결론: 미분의 역할과 계산 최적화

✅ **미분은 변화량을 측정하고, 최적화 및 근사 계산에 활용된다.**  
✅ **최적화 문제에서는 경사 하강법(Gradient Descent)이 중요한 역할을 한다.**  
✅ **컴퓨터 계산을 줄이기 위한 방법 → DP (동적 계획법)과 메모이제이션 활용 가능.**

---

## **📌 참고**

- **위키백과: 미분 연산자** ([링크](https://en.wikipedia.org/wiki/Differential_operator))
- **선형 회귀와 경사 하강법에 대한 추가 자료** ([링크](https://en.wikipedia.org/wiki/Gradient_descent))
- **푸리에 변환과 신호 처리** ([링크](https://en.wikipedia.org/wiki/Fourier_series))

---

🚀 **이제 미분 개념을 정리하고, 수학을 스케일업하여 다변수 함수 분석으로 확장하자!** 😊
