# 퍼셉트론(Perceptron) 정리

## 1. 퍼셉트론이란?
퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 인간 뉴런의 동작을 모방한 알고리즘이다. 1958년 프랑크 로젠블랫(Frank Rosenblatt)이 제안하였다.

## 2. 단층 퍼셉트론(Single-Layer Perceptron)
- 선형 분류 모델로 동작하며, 다수의 입력을 받아 가중치와 곱한 뒤, 활성화 함수를 통해 출력값을 결정한다.
- **구성 요소**
  - 입력 벡터(\( x_1, x_2, ..., x_n \))
  - 가중치(\( w_1, w_2, ..., w_n \))
  - 바이어스(\( b \))
  - 활성화 함수(\( f \))

수식으로 표현하면 다음과 같다:
\[
    y = f\left( \sum_{i=1}^{n} w_i x_i + b \right)
\]

- **활성화 함수**: 계단 함수(Heaviside Step Function)를 주로 사용
  \[
  f(x) = \begin{cases} 1, & x \geq 0 \\ 0, & x < 0 \end{cases}
  \]
- 단층 퍼셉트론은 AND, OR 연산은 해결할 수 있지만 XOR 문제를 해결할 수 없다. 이는 단층 퍼셉트론이 **선형 분리 가능한 문제**만 해결할 수 있기 때문이다.

## 3. 다층 퍼셉트론(Multi-Layer Perceptron, MLP)
- 여러 개의 퍼셉트론을 쌓아 만든 모델로, **은닉층(hidden layer)**이 추가된다.
- 비선형 활성화 함수(시그모이드, ReLU 등)를 사용하여 XOR과 같은 비선형 문제를 해결할 수 있다.
- 역전파(Backpropagation) 알고리즘을 통해 가중치를 최적화한다.

## 4. 퍼셉트론 학습 알고리즘
퍼셉트론은 가중치를 조정하면서 학습하는데, 다음과 같은 알고리즘을 따른다.
1. **가중치 초기화**: 작은 랜덤 값으로 초기화
2. **출력 계산**: 가중치와 입력의 선형 결합을 구한 후 활성화 함수를 적용하여 출력 계산
3. **오차 계산**: 목표 값과의 차이를 계산
4. **가중치 업데이트** (학습률 \( \eta \) 사용)
   \[
   w_i \leftarrow w_i + \eta (y_{target} - y_{output}) x_i
   \]
   \[
   b \leftarrow b + \eta (y_{target} - y_{output})
   \]
5. **반복**: 위 과정을 지정된 횟수(epoch)만큼 반복

## 5. 퍼셉트론의 한계와 극복 방법
### 한계
- 단층 퍼셉트론은 **선형적으로 분리 가능한 문제만 해결 가능** (예: AND, OR는 가능하지만 XOR는 불가능)
- 비선형 문제를 해결하려면 다층 퍼셉트론(MLP)이 필요

### 극복 방법
- 다층 퍼셉트론(MLP) 도입
- 비선형 활성화 함수 사용 (ReLU, Sigmoid, Tanh 등)
- 역전파(Backpropagation) 알고리즘 사용하여 가중치 학습

## 6. 결론
퍼셉트론은 딥러닝의 기초가 되는 모델로, 단층 퍼셉트론은 선형 문제만 해결할 수 있지만, 다층 퍼셉트론을 사용하면 비선형 문제까지 해결할 수 있다. 퍼셉트론 개념을 이해하면 신경망의 기초를 탄탄히 다질 수 있다.
